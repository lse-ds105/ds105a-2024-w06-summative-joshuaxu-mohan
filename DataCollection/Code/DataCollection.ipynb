{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBJECTIVE:** Collect weather data from the OpenMeteo API and save to a JSON file.\n",
    "\n",
    "**AUTHOR:** Joshua Xu\n",
    "\n",
    "**LAST EDITED:** 2024-10-26\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "In this notebook, I will focus on using [Open-Meteo API](https://open-meteo.com/en/docs) to extract weather from London and cities we are comparing it against.\n",
    "\n",
    "URL of [Historical Weather Data](https://open-meteo.com/en/docs/historical-weather-api): `https://archive-api.open-meteo.com/v1/archive`\n",
    "\n",
    "The world cities with their coordinates are found **[here](https://github.com/joelacus/world-cities/blob/main/world_cities.csv)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieving Data from OpenMeteo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define a function which returns historical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function will take inputs of latitude, longitude to return weather data\n",
    "def get_historical_data(latitude, longitude):\n",
    "\n",
    "# Defining parameters \n",
    "    base_historic_url =  \"https://archive-api.open-meteo.com/v1/era5?\"\n",
    "    params_lat_long = \"latitude=\" + str(latitude) + \"&longitude=\"  + str(longitude)\n",
    "    params_date = \"&start_date=2023-01-01&end_date=2024-01-01\"\n",
    "\n",
    "# Defining parameters measuring 'raininess'\n",
    "    params_others = \"&hourly=&daily=weather_code,precipitation_sum,rain_sum,showers_sum,precipitation_hours\"\n",
    "\n",
    "# Define variable combining parameters \n",
    "    final_url = base_historic_url + params_lat_long + params_date + params_others\n",
    "\n",
    "# Define variable for retrieved data from constructed url\n",
    "    response = requests.get(final_url)\n",
    "\n",
    "# Convert data to json file\n",
    "    historical_data = response.json()\n",
    "\n",
    "# Filter data\n",
    "    historical_raininess = historical_data['daily']\n",
    "\n",
    "# Return data\n",
    "    return historical_raininess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain London's historical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_raininess = get_historical_data('51.5085', '-0.1257')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is tedious to search for the coordinates of cities to input. Let's try to automate this.\n",
    "\n",
    "## 2. Automate Coordinate Extraction\n",
    "\n",
    "We can automate the process with the following code to obtain the coordinates after inputting cities and country codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing text file of world cities and coordinates\n",
    "def get_coord(country_code, city_name):\n",
    "    with open('../../world_cities.csv') as file:\n",
    "\n",
    "# Splitting data via line breaks\n",
    "            lines = file.read().split('\\n')\n",
    "        \n",
    "# Splitting data into elements to be sorted into a list of a dictionary  \n",
    "    dict_list = []\n",
    "\n",
    "    for line in lines:\n",
    "        line_elements = line.split(',')\n",
    "        if len(line_elements) != 4: \n",
    "             pass # adjust for errors arising from empty line\n",
    "        else:\n",
    "            current_dictionary = {\n",
    "            'cities_name': line_elements[1],\n",
    "            'country_code': line_elements[0],\n",
    "            'latitude': line_elements[2],\n",
    "            'longitude': line_elements[3]\n",
    "            }\n",
    "            dict_list.append(current_dictionary)\n",
    "\n",
    "# Filtering dictionaries to look for coordinates of inputted latitude and longitude\n",
    "    for dict in dict_list:\n",
    "        if dict['cities_name'] == str(city_name) and dict['country_code'] == str(country_code):\n",
    "            return dict['latitude'], dict['longitude']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(city_name, country_code):\n",
    "\n",
    "    with open('../Data/world_cities.csv') as file:\n",
    "\n",
    "            lines = file.read().split('\\n')\n",
    "        \n",
    "    dict_list = []\n",
    "\n",
    "    for line in lines:\n",
    "        line_elements = line.split(',')\n",
    "        if len(line_elements) != 4: \n",
    "             pass \n",
    "        else:\n",
    "            current_dictionary = {\n",
    "            'cities_name': line_elements[1],\n",
    "            'country_code': line_elements[0],\n",
    "            'latitude': line_elements[2],\n",
    "            'longitude': line_elements[3]\n",
    "            }\n",
    "            dict_list.append(current_dictionary)\n",
    "    for dict in dict_list:\n",
    "        if dict['cities_name'] == str(city_name) and dict['country_code'] == str(country_code):\n",
    "            latitude = dict['latitude']\n",
    "            longitude = dict['longitude'] # define valuables used for codes to follow\n",
    "\n",
    "    base_historic_url =  \"https://archive-api.open-meteo.com/v1/era5?\"\n",
    "    params_lat_long = \"latitude=\" + str(latitude) + \"&longitude=\"  + str(longitude)\n",
    "    params_date = \"&start_date=2023-01-01&end_date=2024-01-01\"\n",
    "\n",
    "    params_others = \"&hourly=&daily=weather_code,precipitation_sum,rain_sum,showers_sum,precipitation_hours\"\n",
    "\n",
    "    final_url = base_historic_url + params_lat_long + params_date + params_others\n",
    "\n",
    "    response = requests.get(final_url)\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    raininess = {\n",
    "         'Date': data['daily']['time'],\n",
    "         'Weather code': data['daily']['weather_code'],\n",
    "         'Precipitation sum': data['daily']['precipitation_sum'],\n",
    "         'Rain sum': data['daily']['rain_sum'],\n",
    "         'Shower sum': data['daily']['showers_sum'],\n",
    "         'Precipitation hours': data['daily']['precipitation_hours']\n",
    "    }\n",
    "    return raininess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, we can collect data from London by simply inputting 'London' and 'GB' to the function and save it to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "london_data = get_data('London', 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our [randomiser](../Sampling/Randomiser.ipynb), we determined that the cities we will be comparing London with are:\n",
    "- Porto-Novo, CV\n",
    "- Kigali, RW\n",
    "- Apia, WS\n",
    "- Tiraspol, MD\n",
    "- Dublin, IE\n",
    "- Ljubljana, SI\n",
    "- Kuwait City, KW\n",
    "- Bangkok, TH\n",
    "- Santo Domingo, CO\n",
    "- Brasiléia, BR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "porto_novo_data = get_data('Porto Novo', 'CV')\n",
    "kigali_data = get_data('Kigali', 'RW')\n",
    "apia_data = get_data('Apia', 'WS')\n",
    "tiraspol_data = get_data('Tiraspol', 'MD')\n",
    "dublin_data = get_data('Dublin', 'IE')\n",
    "ljubljana_data = get_data('Ljubljana', 'SI')\n",
    "kuwait_city_data = get_data('Kuwait City', 'KW')\n",
    "bangkok_data = get_data('Bangkok', 'TH')\n",
    "santo_domingo_data = get_data('Santo Domingo', 'CO')\n",
    "brasileia_data = get_data('Brasiléia', 'BR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging them into a *MEGA* dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_dict = {\n",
    "    'London': london_data,\n",
    "    'Porto Novo': porto_novo_data,\n",
    "    'Kigali': kigali_data,\n",
    "    'Apia': apia_data,\n",
    "    'Tiraspol': tiraspol_data,\n",
    "    'Dublin': dublin_data,\n",
    "    'Ljubljana': ljubljana_data,\n",
    "    'Kuwait City': kuwait_city_data,\n",
    "    'Bangkok': bangkok_data,\n",
    "    'Santo Domingo': santo_domingo_data,\n",
    "    'Brasiléia': brasileia_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Saving Collected Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can then be saved as a JSON file to be further analysed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/london_data.json\", \"w\") as file:\n",
    "    json.dump(london_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/all_data.json\", \"w\") as file:\n",
    "    json.dump(mega_dict, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "As shown previously, the above code can be run immediately in this notebook as such. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run get_data.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
